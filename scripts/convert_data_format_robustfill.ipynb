{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data has been saved to split_test_data.jsonl.\n"
     ]
    }
   ],
   "source": [
    "'''split robustfill data (particularly for data in exedec) into train and test'''\n",
    "import json\n",
    "\n",
    "# Load the JSONL data from the file\n",
    "input_file = '/Users/fengwenjun/Desktop/CODE/Code_Resoning/code_reasoning/data/inductive/COMPOSE_NEW_OP.jsonl'\n",
    "output_file = 'split_test_data.jsonl'\n",
    "\n",
    "data = []\n",
    "with open(input_file, 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# Process each entry to split test_problem data\n",
    "split_data = []\n",
    "for entry in data:\n",
    "    test_problem = entry['test_problem']\n",
    "    inputs = test_problem['inputs']\n",
    "    outputs = test_problem['outputs']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    half_index = len(inputs) // 2\n",
    "    train_inputs = inputs[:half_index]\n",
    "    train_outputs = outputs[:half_index]\n",
    "    test_inputs = inputs[half_index:]\n",
    "    test_outputs = outputs[half_index:]\n",
    "    \n",
    "    # Create new entry with split data\n",
    "    new_entry = {\n",
    "        \"index\": entry[\"index\"],\n",
    "        \"train\": {\n",
    "            \"inputs\": train_inputs,\n",
    "            \"outputs\": train_outputs,\n",
    "            \"program\": test_problem[\"program\"]\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"inputs\": test_inputs,\n",
    "            \"outputs\": test_outputs,\n",
    "            \"program\": test_problem[\"program\"]\n",
    "        },\n",
    "        \"few_shot_examples\": entry[\"few_shot_examples\"]\n",
    "    }\n",
    "    split_data.append(new_entry)\n",
    "\n",
    "# Save the new JSONL data with split test_problem data into a new file\n",
    "with open(output_file, 'w') as file:\n",
    "    for entry in split_data:\n",
    "        file.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "print(f\"Split data has been saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data has been saved to DC_usable_data.jsonl.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSONL data from the file\n",
    "input_file = '/Users/fengwenjun/Desktop/CODE/Code_Resoning/code_reasoning/data/inductive/Deepcoder.jsonl'\n",
    "output_file = 'DC_usable_data.jsonl'\n",
    "\n",
    "data = []\n",
    "with open(input_file, 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "split_data = []\n",
    "for entry in data:\n",
    "    # Extract inputs and outputs\n",
    "    test_problem = entry['test_problem']\n",
    "    inputs = test_problem['inputs']\n",
    "    outputs = test_problem['outputs']\n",
    "\n",
    "    # Determine the number of samples\n",
    "    num_samples = len(outputs)\n",
    "\n",
    "    # Generate indices and shuffle them\n",
    "    indices = list(range(num_samples))\n",
    "\n",
    "    # Split indices into halves\n",
    "    mid_point = num_samples // 2\n",
    "    train_indices = indices[mid_point:]\n",
    "    test_indices = indices[:mid_point]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_inputs = {key: [inputs[key][i] for i in train_indices] for key in inputs}\n",
    "    train_outputs = [outputs[i] for i in train_indices]\n",
    "\n",
    "    test_inputs = {key: [inputs[key][i] for i in test_indices] for key in inputs}\n",
    "    test_outputs = [outputs[i] for i in test_indices]\n",
    "    # Create new entry with split data\n",
    "    new_entry = {\n",
    "        \"index\": entry[\"index\"],\n",
    "        \"train\": {\n",
    "            \"inputs\": train_inputs,\n",
    "            \"outputs\": train_outputs,\n",
    "            \"program\": test_problem[\"program\"]\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"inputs\": test_inputs,\n",
    "            \"outputs\": test_outputs,\n",
    "            \"program\": test_problem[\"program\"]\n",
    "        },\n",
    "        \"few_shot_examples\": entry[\"few_shot_examples\"]\n",
    "    }\n",
    "    split_data.append(new_entry)\n",
    "    \n",
    "# Save the new JSONL data with split test_problem data into a new file\n",
    "with open(output_file, 'w') as file:\n",
    "    for entry in split_data:\n",
    "        file.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "print(f\"Split data has been saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 0, 0, 0, 0], [0, 0, 0, 6, 0], [0, 0, 6, 0, 4], [0, 0, 0, 0, 0], [0, 6, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "a=[[1, 1, 1, 1, 1], [1, 6, 6, 6, 6], [1, 6, 6, 6, 6], [1, 6, 6, 6, 6], [1, 6, 6, 6, 6]]\n",
    "program = 'def fn(grid):\\n    if not grid or not grid[0]:\\n        return []\\n\\n    num_rows = len(grid)\\n    num_cols = len(grid[0])\\n\\n    # Step 1: Identify the largest number in each column\\n    largest_in_col = [max(grid[row][col] for row in range(num_rows)) for col in range(num_cols)]\\n\\n    # Step 2: Find the first occurrence of the largest number in each column\\n    first_occurrence_positions = []\\n    for col in range(num_cols):\\n        for row in range(num_rows):\\n            if grid[row][col] == largest_in_col[col]:\\n                first_occurrence_positions.append((row, col))\\n                break\\n\\n    # Step 3: Create a new grid with 0s, except for the identified positions\\n    result_grid = [[0] * num_cols for _ in range(num_rows)]\\n    for row, col in first_occurrence_positions:\\n        result_grid[row][col] = grid[row][col]\\n\\n    return result_grid\\n\\n# Example usage:\\ninput_grid = [\\n    [2, 0, 3, 0, 2],\\n    [0, 2, 4, 6, 0],\\n    [0, 3, 6, 0, 4],\\n    [0, 2, 0, 2, 0],\\n    [0, 6, 4, 0, 4]\\n]\\n\\noutput_grid = fn(input_grid)\\nprint(output_grid)'\n",
    "exec(program)\n",
    "m = eval(f'fn({a})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0, 0, 0], [0, 6, 6, 6, 6], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codereasoning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
